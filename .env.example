# =====================================================
# JIRA CONFIGURATION
# =====================================================

# Base URL of your Jira instance.
# Cloud example: https://yourcompany.atlassian.net
# Server example: https://jira.yourcompany.com
JIRA_BASE_URL=https://yourcompany.atlassian.net

# Auth mode: "cloud" (email + API token) or "server" (PAT bearer).
JIRA_AUTH_MODE=cloud

# Atlassian account email (required for cloud auth).
JIRA_EMAIL=you@example.com

# API token (cloud) or Personal Access Token (server/DC).
JIRA_API_TOKEN=your-api-token-here

# JQL filter for fetching issues (default: assigned to current user).
# Example to fetch team issues:
# JIRA_JQL=project = ABC ORDER BY updated DESC
# JIRA_JQL=assignee in membersOf("Team") ORDER BY updated DESC
# JIRA_JQL=assignee=currentUser() ORDER BY updated DESC

# Request timeout in seconds.
# JIRA_TIMEOUT=30

# Max retries on 429/5xx.
# JIRA_MAX_RETRIES=3

# =====================================================
# BLOCKED DETECTION
# =====================================================

# Comma-separated link type names that indicate blocking.
# BLOCKED_LINK_KEYWORDS=is blocked by,Blocked,depends on

# Custom field name for impediment/flag (optional).
# BLOCKED_FLAG_FIELD=customfield_10100

# =====================================================
# AI CONFIGURATION
# =====================================================

# AI provider: "ollama" or "huggingface".
AI_PROVIDER=ollama

# Ollama host URL.
OLLAMA_HOST=http://localhost:11434

# Default model (general purpose). Use "auto" to pick from AI_MODELS.
AI_MODEL_DEFAULT=llama3.1:8b-instruct-q4_K_M

# Fast model (quick responses, lower quality).
AI_MODEL_FAST=phi3:mini

# Reasoning model (better analysis, slower).
AI_MODEL_REASON=phi3:mini

# Heavy model (best quality, needs more resources).
AI_MODEL_HEAVY=phi3:medium

# Optional: single list of models with strength.
# Format: name=strength, use trailing "*" to mark default.
# You can tag provider with @local or @groq (default is local).
# If AI_MODEL_DEFAULT=auto, the default will be chosen from AI_MODELS.
# In the Advisor UI, Groq-only mode shows only @groq models.
# Example (local + Groq):
# AI_MODELS=llama3.1:8b-instruct-q4_K_M@local=5*,phi3:mini@local=1,phi3:medium@local=3,llama-3.1-8b-instant@groq=4
# If AI_MODEL_DEFAULT=auto, the default will be chosen from AI_MODELS.
# AI_MODELS=

# Skip local LLM and route directly to Groq (true/false).
# AI_SKIP_LOCAL=false

# Groq API key (required for Groq routing). If you see "Groq authentication failed",
# the key may be expired or revoked.
# GROQ_API_KEY=your-groq-api-key

# Groq API base URL (OpenAI-compatible).
# GROQ_BASE_URL=https://api.groq.com

# Default Groq model.
# GROQ_MODEL_DEFAULT=llama3.1-8b-instant

# =====================================================
# ADVISOR PROMPT OPTIONS
# =====================================================

# Include current task description in advisor prompt.
# ADVISOR_INCLUDE_CURRENT_DESCRIPTION=true

# Include subtask descriptions in advisor prompt.
# ADVISOR_INCLUDE_SUBTASK_DESCRIPTIONS=false

# Include parent description in advisor prompt.
# ADVISOR_INCLUDE_PARENT_DESCRIPTION=false

# =====================================================
# MODEL STORAGE PATHS
# =====================================================

# Ollama models directory (Ollama default: ~/.ollama/models).
# OLLAMA_MODELS_DIR=~/.ollama/models

# Hugging Face / GGUF model directory.
# GGUF_MODEL_DIR=~/.cache/taskforge/models

# HF cache directories (usually auto-detected).
# HF_HOME=~/.cache/huggingface
# TRANSFORMERS_CACHE=~/.cache/huggingface/transformers
# HUGGINGFACE_HUB_CACHE=~/.cache/huggingface/hub

# =====================================================
# PATHS
# =====================================================

# Output directory (generated).
# OUTPUT_DIR=out

# Data directory (snapshots + SQLite).
# DATA_DIR=data

# =====================================================
# LOGGING
# =====================================================

# Logging level: DEBUG, INFO, WARNING, ERROR.
# LOG_LEVEL=INFO

# Log file path.
# LOG_FILE=logs/taskforge.log

# JSON logs (true/false).
# LOG_JSON=false
